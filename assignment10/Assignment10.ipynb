{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.复习上课内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 回答一下理论题目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What is independent assumption in Naive bayes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "Naive Bayes is so called because the independence assumptions we have just made are indeed very naive for a model of natural language. The conditional independence assumption states that features are independent of each other given the class.   \n",
    "Definition: X is conditionally independent of Y given Z, if the probability distribution governing X is independent of the value of Y, given the value of Z   \n",
    "$$\\forall(i,j,k) P(X=x_{i}|Y=y_{j},Z=z_{k}) = P(X=x_{i}|Z=z_{k}) $$\n",
    "Which we often write \n",
    "$$P(X|Y,Z) = P(X|Z)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What is MAP(maximum a posterior) and ML(maximum likelihood) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "假设D是观测数据，H是假设空间，那么有\n",
    "    $$h_{MAP} = arg \\max_{h \\epsilon H} P(h|D)=arg \\max_{h \\epsilon H} \\frac{P(D|h)P(h)}{P(D)}=arg \\max_{h \\epsilon H}P(D|h)P(h)$$\n",
    "$h_{MAP}$即为最大后验概率，表征假设空间内最可能的h的概率。  \n",
    "令上式中的P(h)为一个常数，即是说假设空间内的所有h的比重是一样的，那么则可将P(h)从式中去掉，该式则可简化为:$$h_{ML} = arg \\max_{h \\epsilon H} P(D|h)$$  \n",
    "\n",
    "称$h_{ML}$为最大似然(ML)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What is support vector in SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "在支持向量机中，距离超平面最近的且满足一定条件的几个训练样本点被称为支持向量.  \n",
    "假设超平面(w,b)能将训练样本正确分类,即对于$(x_{i},y_{i})\\epsilon D$, 若$y_{i}=+1$,则有$w^{T}x_{i}+b>0$;若$y_{i}=-1$,则有$w^{T}x_{i}+b<0$.令$$\\left\\{\n",
    "\\begin{aligned}\n",
    "w^{T}x_{i}+b \\geq +1, y_{i}=+1; \\\\\n",
    "w^{T}x_{i}+b \\leq -1, y_{i}=-1. \n",
    "\\end{aligned}\n",
    "\\right.$$\n",
    "距离超平面最近的几个使上式成立的训练样本点就成为\"支持向量\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What is the intuition behind SVM ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "给定有一批训练集,需要将不同类别的样本分开,而能将训练样本分开的超平面可能有很多,需要选出最好的一个,直观上看应该是找位于正中间的划分超平面,如图中红色的平面.\n",
    "SVM要做的剧场通过已有的数据找到这个超平面将数据划分为正样本和负样本,当有新的数据输入时,可也测判断出输入属于正样本还是负样本. \n",
    "![avatar](./svm-demo.jpg)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Shortly describ what 'random' means in random forest ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "随机森林指的是利用多棵树对样本进行训练并预测的一种分类器, 是Bagging的一个扩展变体。其随机的含义主要体现在两个方面：    \n",
    "1) 样本的随机: 训练时的样本是从初始样本随机采样得到的。  \n",
    "2) 属性的随机：训练时随机选取样本的若干个特性进行训练。  \n",
    "因此，随机森林中基学习器的多样性不仅来自样本的扰动，还来自属性的扰动，最终使得集成的泛化性能可通过个体学习器之间的差异度增加来提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. What cariterion does XGBoost use to find the best split point in a tree ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "寻找最佳分割点的大致步骤如下:  \n",
    "1) 遍历每个结点的每个特征；  \n",
    "2) 对每个特征，按特征值大小将特征值排序；  \n",
    "3) 线性扫描，找出每个特征的最佳分裂特征值；  \n",
    "4) 在所有特征中找出最好的分裂点(分裂后增益最大的特征及特征值);   \n",
    "增益的定义如下：  \n",
    "$$𝐺𝑎𝑖𝑛= \\frac {1}{2} [\\frac {𝐺_𝐿^2}{𝐻_𝐿+𝜆}+ \\frac{𝐺_𝑅^2}{𝐻_𝑅+𝜆}−\\frac {(𝐺_𝐿+𝐺_𝑅 )^2}{(𝐻_𝐿+𝐻_𝑅+𝜆)}]−𝜆 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Practial part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem description: In this part you are going to build a classifier to detect if a piece of news is published by the Xinhua news agency (新华社）."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hints:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Firstly, you have to come up with a way to represent the news. (Vectorize the sentence, you can find different ways to do so online)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Secondly,  pick a machine learning algorithm that you think is suitable for this task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! You have completed all assignments in this week. The question below is optional. If you still have time, why don't try it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try differnt machine learning algorithms with different combinations of parameters in the practical part, and compare their performances (Better use some visualization techiniques)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
