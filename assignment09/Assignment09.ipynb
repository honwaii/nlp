{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.思考在自然语言处理中如何发掘模型的可解释性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "深度学习的相关模型普遍都存在可解释性的不强的问题，针对输入和生成的结果，无法准确的判断哪些特征是有用的，哪些特征是无用的，这在实际的业务应用中，可能产生一些意想不到的结果，带来不可估量的损失。因此为了模型的可靠性，保证业务的顺利，可能不得不采用一些方法来打破模型的黑盒，进行观察和处理。以下是搜集查询获取到的对自然语言处理模型解释性方面的一些想法：\n",
    "1) 基于语言特征: \n",
    "深度学习模型的解释性目前是针对模型参数等的可视化上，不同的feature map, 不同的卷积/隐藏层数等，捕获训练中的梯度和损失的情况等等，通过对这些进行可视话来判定各个特征的影响，其主要集中在模型如何计算，如何纠正这些方面。但在自然语言中，这没有涉及到语言本身的特性，许多特性需要提供大量的数据集，由模型本身自己去提取其中的特征信息，而\n",
    "语言本身有既定的一些特点，模型的在特征提取时反而可能会丢失或降低相关特征。NLP的可解释性，应该与我们的语言直觉相一致，从模型、算法的输入，到每个处理环节，再到最终的输出，都可以用基本的语言特征和语言结构来解释。比如用词向量计算词语关联，计算“高兴”的关联词语时，给出“兴奋”、“嗨起来”这样的结果，是符合语言知识的，但如果给出“伤心”这样的结果，即使概率值再高，也是不合理的、不可解释的，因为“伤心”与“高兴”是反义词，虽然他们的上下文环境经常很类似。更进一步来说，“不伤心”这样的搭配，“不”作为否定词，在词向量中如何表示，是否和“高兴”有关联，这是基本常识的对错问题，而不仅仅是概率大小的解释问题。\n",
    "\n",
    "2) 与领域知识应有明确的因果关系\n",
    "可解释性和应用场景强相关。应用场景的知识，决定着NLP的需求边界、任务类型、结果预期等内容，与场景知识之间有明确的因果关系，才是可解释的。\n",
    "因果关系的简单表示就是“因为A，所以B”，比如在快递客服的场景下，对这样的一段文字“等了2个小时还没有来取件”，因为其中有“等待时间长”（从“等了2个小时”这样的文字中得到）和“没有取件”这样的概念，所以这段文字的投诉分类是“取件延误”。与因果关系容易混淆的是相关性（或相似性），比如数据中发现，购买尿布的用户更容易购买啤酒，这说明“啤酒与尿布”之间有相关性，但是“啤酒与尿布”之间没有因果关系。目前常用的机器学习算法（包括深度学习），输出的都是相关性，对这些相关性所体现的领域知识进行解释，是当前可解释性的主流。但这种解释面临着“千人千面”的困境，在同样的应用场景下，针对不同的训练语料、采取不同的算法，其给出的结果差异很大，一致性很难保证。NLP的可解释性，最低的要求是，领域知识与输出结果之间的因果关系是一致的、稳定的。比如在快递客服场景中，针对“取件延误”的投诉分类，不管采用什么算法，也不管文字表达的多样性多么复杂（如“取件的人怎么还不来啊”、“2个小时都过了还没有来取件”等），只要文字表达的意义一样，都包含“等待时间长”“没有取件”这样的概念，都应该给出一致的结果（“取件延误”）。\n",
    "\n",
    "3) 应该追求处理结果的可解释性，而非NLP算法过程的可解释性\n",
    "当前的可解释性，更多的是对算法过程的去魅，希望通过揭示算法过程中的逻辑性，来证明输出结果的合理性。解释的重点主要在于中间过程所产生的特征的相关性、具体参数值对结果的影响等。这些工作对算法的改进无疑有帮助，但对不懂算法的业务人员来说，要从动辄上亿的参数中，找到与具体业务知识的因果性或相关性，真的只能是“雾里看花”了。应该将重点放到对输出结果的可解释性，承认算法过程是个黑盒子，对输出结果做好统筹规划。通过对训练语料的控制，尽可能的缩小每个模型的覆盖范围，把不确定性限制在每个模型内部。换句话说，不能追求对大模型的拟合过程和具体参数值的解释，而应该将一个问题，拆分成多个小模型来表示，提高小模型与领域知识之间的因果关系。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.在Seq2Seq和注意力机制中如何可视化模型细节"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "Sequence-to-sequence（序列到序列）是一种深度学习模型，通过输入一个序列（如词，段落，图片特征等等），然后输出一个序列的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.对抗样本能否运用到自然语言处理模型中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.复现Kaggle心脏病数据集冠军kernel，理解所用的模型可解释性技巧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
